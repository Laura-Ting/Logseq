- 我做过的研究都涉及哪些
	- 3月-6月：在线gaussian-slam开始，splatam和monogs.
		- 在线结束之后在本身的基础上加后提升并不明显。不同方法结论也不一致。
	- 7月：如何高保真，高精度建图？优化桌子。对3dgs不同模块的优化：source data, initialization，render, loss, ADC。结论？
	- 7月-9月：主动建图
		- 项目的贡献：
			- • A novel system that actively splats Gaussians of interest to build a unified, autonomous, and high-fidelity reconstruction system.
			  • A hybrid map representation combining dense predictions of Gaussians and sparse abstraction of Voronoi graph for comprehensive viewpoint selection and safe path planning.
			  • A hierarchical planning strategy based on the Voronoi graph prioritizes local areas to minimize redundant exploration, decoupling viewpoint selection to balance exploration efficiency and reconstruction accuracy.
		- 我的贡献：work with Yuetao Li,
			- investigate the impact of various planning strategies on exploration efficiency
			- assess how different parameter representations in offline optimization enhance online reconstruction results
	- 8月：目标导航
		- 项目的贡献：
			- • Adopt experience replay-based continual learning for online grounding high-dimensional semantic features into neural radiance field,
			  providing universal guidance for goals specified by different modalities.
			  • Extract graph from dense field for efficient path planning, designing a navigation strategy that offers instance-wise semantic
			  guidance and considers uncertainty and safety.
		- 我的贡献：work with Mengying Lin
			- identify key module deficiencies impacting open-set object detection accuracy and system generalization
	- 11-12月：评估(3个级别的评估指标)，scene graph(hovsg, clio)。
		- develop a comprehensive evaluation framework assessing top-k precision and recall。unified framework
		-
	- 动态场景也可以说scene graph
		- 场景图是一种结构化表示方法，可以有效捕捉场景中对象及其关系。通过动态更新场景图，系统可以实时反映场景的变化，如物体的移动、新物体的加入或现有物体的移除。这种结构化表示对于理解动态环境非常关键。
		- 场景图可以用于识别需要特别关注的动态区域，从而优化资源分配和计算效率。
	-
	- 我能用到的研究
		- 仿真器的交互需要人和仿真场景交互：人对场景的操作（如编辑、控制）会引发场景物体位置或状态的改变，而这些变化需要高效的表示和反馈。
		- 数字资产，场景物体解耦，编辑和控制
			- 数字资产（场景物体的几何、位置、语义信息等）被解耦并独立管理，为动态场景中的资产变化（新增、移除、编辑等）提供支持
			- eg：自动的物体摆放整齐：需要通过动态生成模型模拟并预测物体的移动路径和最终状态，从而实现更自然的交互效果
			- 将场景分为静态背景和动态前景模型（场景的环境部分通常是恒定的，例如房间布局等，物体位置、状态或交互信息则是动态变化的，例如人物移动或家具重新排列。）
		- 主动建图是为了主动获取环境中的数字资产。
			- 它需要根据环境的实时变化调整探测路径和策略。如何在动态场景中识别关键资产（例如动态物体）并优先进行高保真重建。
			- 在动态场景中，环境会随着时间不断变化，主动建图需要动态调整策略以适应这些变化。
			- 在动态场景中，主动建图方法需要实时感知环境的变化，例如动态前景物体的移动或交互触发的事件，并更新建图策略。
			- 基于当前场景变化，主动建图可以优先捕获动态变化区域的数字资产，从而提高对动态场景的整体建模效率。（主动建图视角是单一的，如何知道全局发生的动态变化，比如说身后的物体发生变化？）
			- 静态场景中的探索策略（路径规划、视点选择）是动态场景中“实时路径调整”的基础。
		- 语义建图是为了获取场景的语义信息。
			- 语义建图是为了捕捉场景中的语义信息，而动态场景中的语义信息会随时间和交互而发生变化，例如对象的状态、属性或关系的改变。如何在动态场景中根据实时变化捕获并更新语义信息，从而维持场景的语义一致性。
			- 静态场景中的语义提取和场景图组织是动态场景中“语义更新和关系表示”的起点。
		- scene graph可以很好地表示动态场景：
			- 动态交互场景中的对象和人类行为需要以时间为序列进行动态建模，场景图（Scene Graph）在这里可以很好地表示物体间的关系和语义结构。静态背景通过场景图中的恒定节点表示，例如固定的建筑结构。动态前景通过场景图中的可变节点和边来动态更新物体位置和关系，例如用户交互后物体移动到新位置。Scene Graph 的使用为动态场景的解析、表示和控制提供了高效的手段，尤其是在语义建图和主动建图中的应用。
		- 动态场景的可泛化性和生成模型
	-
	-
	- 你现有的研究方法（主动建图、语义建图）虽然针对静态场景，但可以通过：
	- **时间维度的加入**（实时更新、动态规划）；
	- **动态物体的处理**（前景-背景分离、动态语义节点更新）；
	- **生成与泛化能力**（利用生成模型预测动态变化），
	-
	- LiDAR-based Online Construction of Structured Radiance Field 这个不一定说
	  collapsed:: true
		- leverage LiDAR's high-precision pose capabilities and hierarchical scene graphs' explicit representation to enhance semantic reasoning accuracy and reconstruction geometry
- Structured-NeRF
  collapsed:: true
	- 在优化语义关系和物理关系时没有考虑对象的时间变化和动态特性（例如运动轨迹、状态变化）
		- 在分层场景图中引入**时间序列节点**，每个对象不仅包含静态的语义和物理属性，还包含其随时间变化的状态（如位置、方向、速度）。
		- 使用时间序列模型（如LSTM、Transformer）对对象之间的语义关系和物理关系的动态变化进行建模。
	- 目前的场景编辑是基于离线推理（如GPT-4/VLM生成的关系），并不适用于实时变化的动态场景。
		- 开发实时更新的场景表示框架，例如在对象或语义关系发生变化时动态更新场景图。
		- 结合在线学习或主动感知技术，让系统能够通过传感器数据实时感知场景变化并更新分层场景图（例如机器人在探索环境时感知到新的对象或对象的移动）
	- 目前的语义优化是基于静态场景的关系推理，未考虑动态场景中语义关系随时间的变化。
		- 在语义优化中加入动态约束，例如：考虑对象的相对运动状态（例如“物体A靠近物体B”）；动态场景中对象的功能性语义变化（例如“物体A从桌子上掉下来”）。
	- 虽然引入了生成模型来推断语义和物理关系，但未将生成模型用于预测动态场景中的变化。
		- 使用生成模型（如Diffusion Models、GANs）生成动态场景的未来状态，预测对象可能的位置和语义关系。
		- 支持动态场景的重构和未来状态模拟，例如“桌上的杯子被推倒后会落在哪里”。
	- 初步实现，仅考虑静态的简单物理关系（如重力、排斥力）
		- 深入模拟动态物理交互，例如碰撞响应、用户拖动对象时的物理反馈。
-
- 这些老师当前的研究的topic都有哪些，宽泛一点的。这些topic之间有什么联系，能够被总结成有关联的最小数目。
-
- 我做过的研究如何能与老师的话题产生联系。
	- 我在我的研究过程中发现什么东西很重要？所以我想去他们的组解决这个问题。
	- 我做过的研究就是这个东西？
-
-
- 用摄像机获取动态场景，并从记录的数据中估计场景的模型描述(形状，运动，物理属性的模型)
- 真实感：结合研究动态场景的获取、重建和显示问题，并为每个问题开发新的算法概念。开发动态形状和外观重建，运动估计，复杂可变形模型的动画，实时渲染和重照明的方法。
-
- Christian Theobalt导师是Hans-Peter Seidel，他本身主要是动态
	- 1, developing methods for acquiring dynamic scenes with video cameras and estimating model descriptions of the scenes from the recorded data. These model descriptions typically comprise of models of shape, models of motion or models of physical material properties.
	- 2, display such model descriptions realistically:  investigate the problems of acquisition, reconstruction and display of dynamic scenes in conjunction and develop novel algorithmic concepts for each of these questions. develop methods for dynamic shape and appearance reconstruction, motion estimation, animation of complex deformable models, and real-time rendering and relighting.
	- 3，generate realistic renderings of image- or video-captured dynamic scenes from arbitrary virtual camera views.
	- One very young line of research that aims at putting this video-based rendering paradigm into practice, is 3D or Free-Viewpoint Video. Here, we will extend our previous work on model-based free-viewpoint video of human actors and develop novel algorithms that enable us to process more general scenes.
	-
- Vladislav Golyanik 动态4DQV
  collapsed:: true
	- general deformable scenes, 3D reconstruction of the human body and matching problems on point sets and graphs
	- neural approaches (both supervised and unsupervised), physics-based methods as well as new hardware and sensors (e.g., quantum computers and event cameras)
	- 3D Reconstruction and Neural Rendering of Rigid and Non-Rigid Scenes
	- 3D Generative Models
	- Quantum Algorithms for Computer Vision and Graphics
	-
- Thomas Leimkühler
  collapsed:: true
	- Machine learning for visual computing
	- Neural signal representations
	- Generative models
	- Data-driven/neural rendering
	- Physically-based rendering
	- Inverse rendering
	- Efficient parallel algorithms
- Gerard Pons-Moll
  collapsed:: true
	- analyzing people in videos, and creating virtual human models by "looking" at real ones. His research has produced some of the most advanced statistical human body models of pose, shape, soft-tissue and clothing (which are currently used for a number of applications in industry and research), as well as algorithms to track and reconstruct 3D people models from images, video, depth, and IMUs.
	- efficiently digitize people and train machines to perceive people from visual data
	- build virtual humans that look, move and eventually think like real ones
-
- Prof. Dr. Bernt Schiele
	- Understanding sensor information is a fundamental problem in computer science. Scientific challenges cover the entire pipeline from single-sensor processing, over spatial and temporal fusion of multiple and divergent sensor modalities to the complete description of large-scale multimodal sensor streams. At the same time we observe a tremendous increase in both the quantity as well as the diversity of sensor information due to the increasing number of sensors (such as cameras, GPS, or inertial sensors) embedded in a wide variety of digital devices and environments as well as due to the increasing storage of multimodal sensor data (such as surveillance data, personal storage of digital information, multimedia databases, or simply the Internet). While storing and indexing large amounts of sensor data has made tremendous progress, understanding of this multimodal sensor data still lacks far behind. Therefore the long-term goal of our research is to make progress on how to process, structure, access and truly understand multi-sensory data both for online use as well as for large-scale databases.
	- The group currently focuses on two main areas of the broader field, namely computer vision and multimodal sensor processing. In the area of computer vision we address some of the most basic functionalities of image and video understanding such as 3D object class recognition or 3D people detection and tracking. We also look at the problem of 3D scene understanding of traffic scenes as a case study for complete scene understanding. In the area of multimodal computing we currently focus on the problem of human activity recognition as a means to study how ubiquitous or wearable computing may benefit from better sensor understanding. As a final cross-cutting theme for both areas we also work in the area of machine learning. It is clear that only advanced machine learning techniques will enable to infer higher-level information from noisy sensor data and enable to deal with the large-scale nature of current and future multimodal databases and sensor-streams.
-
- Dr. Marc Habermann
  collapsed:: true
	- Our group conducts research at the intersection of Computer Vision, Computer Graphics, and Machine Learning. One long term goal and vision is to develop algorithms, which enable a complete analysis of dynamic and detailed humans. This, for example, involves 4D capture of the human surface, motion capture, lighting estimation, and surface appearance capture. However, not only the analysis of humans is in the focus of our research, but our group also explores new techniques for photorealistic human synthesis by combining concepts from Graphics, Vision, and Machine Learning.
	  In summary, our research interests include but are not limited to:
	- Human performance capture
	- Human synthesis
	- Body, hand, and face capture
	- Physics-based capture
	- Motion synthesis and human scene interaction
	- Dynamic neural scene representations
	- Differentiable rendering
-
- 1, What concrete problem do you want to solve within the scope of dynamic scene?
- 2, Why and how do you want to solve it?
- 3, What are your expected outcomes and goals?
- 4, Add any relevant references (preferably papers by you)
-
- 都是data-driven，从data中学习数据。我们也是从视频中学习，或者直接跟人学习。
-
- A cover letter describing your current or latest accomplished study programme and university, your estimation of the relevant background and experience and what type of position you are interested in
-
- Research statement, i.e., at most a page-long description of your research interests and plans, including why you are interested in working at/with 4DQV
-
-
- statement of purpose：选择这个专业/项目的原因，过往的相关经历，从经历中获得了什么，感兴趣的方向，未来发展规划
-
- 我们周围的世界是动态的
- 人对场景的操作（如编辑、控制）会引发场景物体位置或状态的改变，而这些变化需要高效的表示和反馈。
- 动态交互场景中的对象和人类行为需要以时间为序列进行动态建模，场景图（Scene Graph）在这里可以很好地表示物体间的关系和语义结构。
-
- 1，我想解决的问题？
  collapsed:: true
	- 如何实现动态场景地图表示的实时更新？
	- 动态场景中的物体位置、状态、语义关系会随时间和交互而不断变化。例如，用户对仿真场景的操作（如拖动物体、重新排列家具）会引发场景物体的状态或关系的改变，这些变化需要被实时捕捉并反馈。
	- 场景中的语义信息（如物体的类别、属性和相互关系）需要在动态变化中保持一致，避免因交互或状态改变导致语义信息的混乱或滞后。
	- 数字资产（如物体的几何、位置、语义信息）需要被解耦并独立管理，以支持用户对场景的实时编辑、控制和预测，例如自动摆放物体、动态调整布局等。
- 2，我为什么想解决这个问题？
  collapsed:: true
	- 随着技术的发展，动态场景的建模与交互在多个领域中变得愈发重要。无论是机器人在复杂环境中的导航与任务执行，动态场景的实时表示与交互都是关键。现有的静态场景方法无法满足这些应用对实时性和灵活性的要求，实时更新比较困难。
	- 人类所生活的世界本质上是动态的，物体、环境和人类行为都在不断变化。为了更好地模拟和理解这个动态世界，我们需要在数字环境中实现对动态场景的高效表示与交互。这不仅是技术发展的需求，也是对现实世界的真实反映。通过研究动态场景的实时语义一致表示与交互，我们可以更接近地模拟现实世界的复杂性，为人类与技术的互动提供更自然的桥梁。
- 3，我用什么方法解决这个问题？
	- 方法上：
	- 首先我想先实现的是高精度这个问题，动态场景中的对象移动、环境变化对建图的精度提出了更高的要求，而高保真建图则是理解和重建复杂动态场景的关键。所以用3d gaussian splatting来解这个问题。
	- **动态场景的时空建图与优化问题**。
	- ### **1. 问题建模：动态场景的时空图结构表示**
		- 动态场景中的核心挑战在于：**如何在动态变化中实时维护语义一致性，同时高效地捕捉和表示变化的区域**。我们可以将动态场景建模为一个 **时间依赖场景图 G_t，它结合了空间（物体和关系）与时间（动态变化）的多模态信息表示。
		- #### **1.1 模型定义**
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/Laura-Ting/blog-images/master/202412232225804.png){:height 294, :width 530}
		- #### **1.2 模型目标**
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/Laura-Ting/blog-images/master/202412232225231.png)
	- ### **2. 方法设计：基于动态场景图的时空更新机制**
		- #### **2.1 核心思路**
			- 我们引入一个 **基于动态场景图的分区更新机制**，以 **局部变化感知** 和 **时空一致性优化** 为核心，设计实时更新框架。
			- **关键创新**：引入一个“**变化感知器（Change Detector）**”模块，能够实时检测动态场景中的变化区域，并仅更新这些区域的场景图，同时通过一个局部优化机制保证语义一致性。
			  
			  ---
		- #### **2.2 变化感知：检测动态区域**
		  动态场景中的变化区域检测（**Change Detection**）是实现实时更新的第一步。我们通过以下方法高效检测变化区域：
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/Laura-Ting/blog-images/master/202412232227799.png){:height 371, :width 1143} 
			  ---
		- #### **2.3 局部语义更新：动态区域的优化机制**
			- 变化区域的语义更新需要确保动态场景图的语义一致性。针对 G_t^{change}*G**t**c**han**g**e*​，我们设计以下两步：
			- **动态关系更新**：
				- 当某个物体节点 v_i*v**i*​ 被感知到位置或状态变化时，我们重新计算其语义关系边 e_{i,j}*e**i*,*j*​ 的属性。
				- 例如，当物体 A 从桌面掉落到地面时，更新其支撑关系：
				  
				  e_{A, table}(t) \rightarrow \emptyset, \quad e_{A, ground}(t) \rightarrow \text{"supported"}*e**A*,*t**ab**l**e*​(*t*)→∅,*e**A*,*g**ro**u**n**d*​(*t*)→"supported"
				- 通过关系分类器（如基于 GNN 的关系预测器）自动推断新的语义关系。
			- **时空一致性优化**：
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/Laura-Ting/blog-images/master/202412232228349.png){:height 394, :width 763} 
				  ---
		- #### **2.4 实时重构与交互反馈**
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/Laura-Ting/blog-images/master/202412232228853.png){:height 219, :width 738}
- 4，我有怎样的预期和目标？
  collapsed:: true
	- 实验上：用什么实验来验证方法的有效性
	- 验证系统在动态场景中的实时更新能力、语义一致性和生成预测能力。
	- Setup：标准动态场景数据集，环境配置
	- Metrics：
		- 实时性（Latency）
			- 定义：从场景变化发生到系统完成更新的时间间隔。
			- 衡量方法：使用高精度计时器记录每次变化的响应时间。
			- 预期结果：系统能够在100ms以内完成更新，确保用户交互的流畅性。
		- 语义一致性（Semantic Consistency）
			- 定义：动态变化后，场景中语义信息的正确性和一致性。
			- 衡量方法：使用语义分割准确率（Accuracy）和一致性度量（Consistency Score），计算变化前后语义标签的一致性。
			- 预期结果：语义一致性得分高于90%，确保语义信息在动态变化中的稳定性。
		- 生成预测准确性（Prediction Accuracy）
			- 定义：生成模型对动态场景未来状态的预测准确性。
			- 衡量方法：计算预测结果与真实变化的均方误差（Mean Squared Error, MSE）。
			- 预期结果：MSE低于0.05，表明生成模型能够准确预测场景变化。
	- 比较基准（Baselines）
		- 静态场景建图方法，现有动态场景方法。评估在相同数据集和环境下，各方法的实时性、语义一致性和生成预测能力
	- 预期结果
		- 实时性：相比静态方法，动态场景方法显著降低延迟，接近或优于现有动态方法。
		- 语义一致性：在动态变化中，系统保持高语义一致性，优于静态方法，并与现有动态方法持平或更优。
		- 生成预测准确性：生成模型能够准确预测场景变化，MSE显著低于现有方法。
- 5，相关参考
  collapsed:: true
	- 仿真器的交互需要人和仿真场景交互：人对场景的操作（如编辑、控制）会引发场景物体位置或状态的改变，而这些变化需要高效的表示和反馈。
	- 数字资产，场景物体解耦，编辑和控制
		- 数字资产（场景物体的几何、位置、语义信息等）被解耦并独立管理，为动态场景中的资产变化（新增、移除、编辑等）提供支持
		- eg：自动的物体摆放整齐：需要通过动态生成模型模拟并预测物体的移动路径和最终状态，从而实现更自然的交互效果
		- 将场景分为静态背景和动态前景模型（场景的环境部分通常是恒定的，例如房间布局等，物体位置、状态或交互信息则是动态变化的，例如人物移动或家具重新排列。）
	- 主动建图是为了主动获取环境中的数字资产。
		- 它需要根据环境的实时变化调整探测路径和策略。如何在动态场景中识别关键资产（例如动态物体）并优先进行高保真重建。
		- 在动态场景中，环境会随着时间不断变化，主动建图需要动态调整策略以适应这些变化。
		- 在动态场景中，主动建图方法需要实时感知环境的变化，例如动态前景物体的移动或交互触发的事件，并更新建图策略。
		- 基于当前场景变化，主动建图可以优先捕获动态变化区域的数字资产，从而提高对动态场景的整体建模效率。
		- 静态场景中的探索策略（路径规划、视点选择）是动态场景中“实时路径调整”的基础。
	- 语义建图是为了获取场景的语义信息。
		- 语义建图是为了捕捉场景中的语义信息，而动态场景中的语义信息会随时间和交互而发生变化，例如对象的状态、属性或关系的改变。如何在动态场景中根据实时变化捕获并更新语义信息，从而维持场景的语义一致性。
		- 静态场景中的语义提取和场景图组织是动态场景中“语义更新和关系表示”的起点。
	- scene graph可以很好地表示动态场景：
		- 动态交互场景中的对象和人类行为需要以时间为序列进行动态建模，场景图（Scene Graph）在这里可以很好地表示物体间的关系和语义结构。静态背景通过场景图中的恒定节点表示，例如固定的建筑结构。动态前景通过场景图中的可变节点和边来动态更新物体位置和关系，例如用户交互后物体移动到新位置。Scene Graph 的使用为动态场景的解析、表示和控制提供了高效的手段，尤其是在语义建图和主动建图中的应用。
	- 动态场景的可泛化性和生成模型
-
- 我目前一直在思考并想解决的一个问题是动态场景地图的实时更新问题，这与许多教授的方向都很吻合。
- 动态：Vladislav Golyanik，Christian Theobalt
- 人与交互：Dr. Marc Habermann，Gerard Pons-Moll。动态问题为什么困难是因为物体的位姿在发生变化后进行位姿估计是困难的，而整个场景本质上是因为人的交互而发生状态的变化的，所以我们可以以人为切入点。通过人来估计动态物体。
- 重建：Thomas Leimkühler
- 人对场景的操作（如编辑、控制）会引发场景物体位置或状态的改变，而这些变化需要高效的表示和反馈。所以我用动态场景图构建，里面有静态节点和动态节点。
-
- 在人体重建和计算机视觉领域，"人是一个很简单的先验"这个说法可以从几个方面来理解，但需要注意的是，这个观点并不意味着人体重建是简单的任务，而是指在某些特定的上下文中，人体的结构特性可以被有效地利用作为先验知识。
- **人体的结构化特征**：
	- 人体具有相对固定的解剖结构，比如头、躯干、四肢等部分的连接关系。这种结构化特性使得我们可以使用骨架模型、关节点等先验知识来指导三维重建过程。
	- 在机器学习和计算机视觉中，这种结构化信息可以简化模型的学习过程，因为模型可以依赖这些已知的几何和拓扑关系来减少计算复杂度。
- **有限的形状变化**：
	- 尽管人体可以采取多种姿态和动作，但整体的形状变化范围是有限的。通过统计建模（如基于形状的模型），可以捕捉人体形状和姿态的变异性，使得模型能够在给定数据的基础上进行合理的预测和插值。
	- 常用的方法包括参数化人体模型（如SMPL模型），这些模型使用少量参数来表示人体的多样性。
- **丰富的标注数据**：
	- 与其他自然场景相比，人体数据集相对丰富且标注良好。这为训练数据驱动的模型提供了强大的支持，使得利用先验知识进行有效的人体重建成为可能。
- **应用领域的专注**：
	- 在许多应用中，如动画、虚拟现实和运动捕捉，人体的主要关注点是动作和姿态，这使得问题可以被简化为特定的任务，比如关节点检测和姿态估计。