- Intro
  collapsed:: true
	- 之前还是高保真建图的应用
	- 高保真建图的challenge，没有实时反馈
	  collapsed:: true
		- 然而，这些方法都是严重依赖数据的。在数据采集不完整的情况下，离线的重建会存在伪影或者空洞。在目前的方法中数据是预先收集好的，目前又没有一种能够对采集的数据进行实时反馈的方法，这就导致人们可能盲目的采集了大量图片但仍有未观测到的视角导致场景重建不完整。
	- 我们想通过搭建一个主动建图系统来从数据收集角度解决这个问题，也就是高保真ASLAM问题，这个算法主要包括两个部分：环境本身的重建和传感器的运动控制。
	  collapsed:: true
		- 第一，我们需要一种场景表征，能够做到实时，逼真渲染，增量式重建，3D Gaussian就是好的选择。
		- 第二，我们需要一种指引的策略，能够告诉agent哪里需要去观测，从而完成整个场景的完整重建。类似于人类的视觉中的眼睛看向某个位置从周围环境中获取信息，agent通过传感器相机在某个视点进行观测来感知周围的环境信息从而完成重建。在自由空间中，视点的个数是无限多的，agent如何选择至关重要。
		- 第三，强调平衡：completeness和efficiency，我们想要实现的是在有限资源的条件下最大化探索效率，当给定agent设备本身有限时这个问题转化为在短时间内把环境探索完整，即给定步数下达到尽可能高的完整度。
	- 我们系统主要由4个模块构成，通过一个unifed Gaussian Splatting framework去完成各个模块的构建。
	  collapsed:: true
		- （1）我们利用在线高斯SLAM系统去实现整个度量高斯地图增量构建和导航拓扑地图的实时更新
		- （2）利用这两个地图对当前观测进行不确定性量化
		- （3）根据不确定性量化结果进行在线视点选择，我们需要选出“好的视点”
		- （4）基于图搜索的路径规划
	- 我们的contribution
	  collapsed:: true
		- 统一的基于Gaussian Splatting的framework，保证高保真
		- 一种新颖的在线视点选择策略，保证自适应粒度，粗粒度完成整个场景的快速探索，细粒度完成更细节的观测
		- 我们在仿真环境gibson和mp3d上对我们的系统进行验证，同时在real-world场景也有较好效果，同时我们的系统可以进行离线处理
-
- Related Work
	- 主动探索
	  collapsed:: true
		- 基于边界的方法利用已探索区域与未探索区域的边界不断扩大探索区域，直至覆盖整个环境。但该方法缺乏全局视角，且具有一定的贪婪性，容易导致策略陷入局部最优。
		- 基于采样的方法涉及随机采样潜在观察点，并基于最大化不确定性或预期信息增益选择最佳视点，从而降低环境不确定性。但该方法通常存在采样效率低和计算成本高的问题。
		- 此外，为了提高整体探索效率，TARE\cite{cao2021tare} 探索使用分层规划，通过沿现有全局路径采样一组视点来有效覆盖局部子空间，从而提高探索效率。 \cite{selin2019efficient} 将使用基于边界的策略的全局探索的优势与通过 Next Best View (NBV) 方法的局部探索的优势相结合。FALCON\todo{paper} 将全局覆盖路径引导与局部边界优化相结合，利用分层规划和在线生成的覆盖路径进一步提高探索效率。然而，这些方法生成的稀疏场景表示（如点云、体素和占用网格）虽然对于导航规划和碰撞检测很有效，但主要关注覆盖率而不是真实感场景构建。
	- 高保真建图
	  collapsed:: true
		- NeRF 采用多层感知器 (MLP) 将空间坐标映射到颜色和密度，利用体积渲染实现高质量的新视图合成。然而，其计算密集型隐式表示导致训练和渲染效率低下。3DGS 通过利用 3D 椭圆体的显式场景表示解决了这个问题，同时保持了可微分渲染。通过采用基于光栅化的点渲染，3DGS 增强了实时、高保真 3D 场景重建。这些方法是被动的，没有实时反馈的数据收集会导致训练数据中出现伪影、漏洞和过度拟合。虽然以前的研究试图通过 Mip-Splatting 等过滤技术来缓解这些问题并减少对大型数据集的依赖，但这并不能从根本上解决问题。
		- 虽然 NeRF 已经应用于主动重建\cite{Yan2023iccv,kuang2024nexplore,pan2022activenerf,lee2022uncertainty}，但其较长的训练时间和较高的计算需求使其不太适合需要快速响应的主动建图任务，并且得到的几何和纹理质量通常不令人满意。详细的定性比较见 \ref{subsec:comparison} 节。
		- 一些方法结合高斯和 SLAM 技术来实现高保真在线实时重建。然而，这通常需要人工干预和大量时间，例如手持扫描仪或无人机 (UAV) 以及手动判断重建不完整的地方，这不是自动化的。
		- 最近还有一项与我们的工作非常相似的工作 GS-planner，但我们用于视点选择的候选集方法更容易获得，并且用于测量不确定性的方法更统一。
-
- Methodology
- 我们利用unify统一的 framework Gaussian Splatting去构建各个module。Section A将介绍稠密高斯地图和拓扑地图结合的双重表示结构，其中gs map用于重建整个三维场景，topology 维诺图用于主动的视点选择和路径规划。Section B将介绍高斯地图是如何在线优化的，这个优化过程是增量式的，可微的，实时的。Section C将介绍我们提出的由在线不确定性评估引导的，能够获取更多信息的在线视点选择选择策略。SectionD关注通过图搜索进行路径规划，以及后续离线进行的优化步骤。
- A，dense 高斯地图和拓扑地图结合的数据结构
  collapsed:: true
	- a，介绍这两种数据结构
	  collapsed:: true
		- gs map用于重建整个三维场景。高斯是一种显式的表征(公式，参数化表示，为了平衡效率做出简化)，这些高斯体可以精确地放置在空间中，以表示场景的几何形状和外观。同时，基于可微渲染和光栅化，可以实现实时的，逼真渲染特性的表示。
		- topology用于主动的视点选择和路径规划。拓扑地图通过节点和边来表示环境的高级结构，其中节点代表关键位置（如房间、门、走廊等），边代表节点之间的连接关系。我们的拓扑地图用维诺图表示，维诺图的边等距点。。。(什么时候引出维诺图比较合适？)
		- 我们后面的所有东西是基于这两种表示。
	- b，两种地图各自特点，互补，复合作用带来的收益很大：
	  collapsed:: true
		- 维度+含义：稠密的gs map是3D的，反映出当前的环境地形和精确的尺寸，精确的位置信息，详细的3D空间信息。拓扑地图是2D的，关注于环境的高级结构，如房间、通道和关键转折点等，它简化了环境的复杂性，便于进行路径规划和快速决策。
		- 尺度+抽象层次：稠密地图适用于局部和详细的操作，而拓扑地图适用于全局和概括性的理解。这种多尺度的表示方法可以帮助机器人在不同的抽象层次上理解和处理环境信息。
	- c，从gs中获取拓扑地图是方便的，实时的，模块复杂度不高，讲述从gs中获取维诺图的过程：
	  collapsed:: true
		- 维诺图代表着agent可通行的path，是通过free space map获取，而free space map是通过visible map和obstacle map计算出的。visible map代表着整个场景的可见区域，包含了可以行走的区域和障碍物，不包括场景外因为我们认为场景以外不可见。obstacle map代表着整个场景的障碍物。我们需要从整个场景的可见区域中去掉障碍物，就是可通行区域。这些图是经过渲染俯视图得到的。
		- 具体来说，我们在场景上方放一个相机，设置fov。。visible map通过渲染机器人身高内的高斯到地板上得到，即整个场景的可见区域。obstacle map通过渲染机器人脚以上的高斯得到，即去掉地板的障碍物。free space map是通过visible map和obstacle map经过二值化之后进行XOR操作得到。free space map再经过膨胀和抽取多边形来得到维诺图。
- B，在线高斯建图优化过程
  collapsed:: true
	- a，高斯致密化
	  collapsed:: true
		- 在哪里加高斯，我们的改动0.5 -> 0.98为了更少的高斯
	- b，地图更新
	  collapsed:: true
		- 渲染出来的和真实的求loss
		  collapsed:: true
			- C和D进行梯度回传，O用于我们后续视点选择
		- 关键帧优化策略，建图迭代次数降为5
- C，在线视点选择
  collapsed:: true
	- a，视点选择的评判
	  collapsed:: true
		- 我们需要提高视点选择的效率，首先我们需要保证我们的视点是安全可达的(不能让agent因为去往这个视点而和周围物体产生碰撞)，其次我们不能从这无限多个视点中选择因为这会增加决策的负担，而且是随着探索空间的逐渐增大这个本身就无限的集合会爆炸式增长。所以我们需要将视点备选的集合从无限个压缩到有限个同时是在不改变整个场景的信息量的情况下，即这些有限个视点依旧能代表整个自由空间。（有限的，代表性的，想想维诺图怎么说，这个不能全部保证）
		- 我们需要选择“好的视点”，对于视点好坏的评定并不绝对，但直观上讲我们认为一个较好的视点含有较多的信息增益[《Viewpoint Selection using Viewpoint Entropy》VMV 2001Stuttgart, Germany, November 21–23, 2001]。这样我们在观测完这些挑选出的有限视点后能获得关于环境的最多的信息(相比于其他选择视点的策略)。
	- b，维诺图作为数据结构
	  collapsed:: true
		- 在这种情况下，我们选择了维诺图作为我们选择视点的重要的数据结构。
		- 首先，维诺图保证安全可达性(不会和障碍物相撞)而且能覆盖所有场景。
		- 其次，我们的维诺图是稀疏的，节点个数有限(position)，在节点上看向的方向(rotation)也是有限的。我们通过position和rotation解耦让整个候选集合变为有限。
		- 而且，维诺图具有拓扑性，能够描述多联通的关系，而多联通节点是不同路径的交汇，这里会潜在的还有更多信息。
		- 维诺图可以通过渲染实时获取。
	- c，如何评估一个视点的信息多少，我们利用不确定性量化来评估信息增益。
	  collapsed:: true
		- 说opacity，render：
			- opacity：当我们选定一个视点渲染出这个视点下的观测，如果这里已经重建好那么这里就有高斯，opacity就大，不确定性就低，这个视点下含有的信息增益就少；同理，没有渲染好的地方没有高斯，这通过opacity低体现出来，这种区域不确定性高，这个视点下含有的信息增益就高，我们需要看向不确定性高的区域去降低整个场景的不确定性，即获取更多信息，具体来说是通过向没有高斯的地方添加高斯来填补空白。
			- render：而利用3dgs的opacity其实就是利用渲染silhouette，渲染可见性，正好是splatam中的，我们进行巧妙利用，而且render实时的特性可以得到在线反馈。 基于视点的渲染，梯度回传，加高斯后得到优化(不确定这个要不要放在渲染里面，splatam那里应该说过这个)。
		- 说panorama：在维诺图的一个节点上，我们如何获得这个节点各个方位的完整的不确定性信息，需要通过360环视去渲染一张全景图。
		- 说opacity+panorama：聚类，
		- 说volume：发现前者视角相关，距离相关，当我们发现一个hole时，由于渲染是视角相关的，具有近大远小的特点，也就是说可能会存在一个距离近的hole opacity为空的像素数量比较大但实际体积比较小，而一个距离远的hole opacity为空的像素数量。所以我们整合3D体积信息去进行更合理的不确定性推断，即加入hole周围一圈包络点云的凸包体积。
	- d，如何遍历这些候选节点让我们的收益最大化，Next Best View问题：我们position和rotation贪心的解耦策略
		- position让我们优先去往不确定性最高的节点，rotation在这个节点看向不确定性最高的方向。自适应粒度：position是粗粒度，rotation是细粒度。可以在这里写position的node scoring策略         “目标驱动？”
		- 同时在去往的路上，我们看向多联通节点不确定性高的方向去获取更多信息。
		- 动态更新每个节点的不确定性信息，这也就是我们的反馈机制，在线反馈和在线决策
- D，路径规划与离线优化
  collapsed:: true
	- a，路径规划
	- b，离线优化
		- 在高斯在线重建之后，我们加入高斯自适应密度控制的优化模块对整个场景进行优化。高斯的表征三维可以转化为二维进行参数扁平化，这使得高斯更加贴合表面。在优化项上，深度正则和法向正则可以被加入去更好地约束表面。
-
- 实验
	- 实验设置
	- 实验A：和NExplore比较
	  collapsed:: true
		- 定性结果
		- 定量结果
	- 实验B：在线-离线优化
	  collapsed:: true
		- 我们验证了在线的结果可以用于离线优化去获得更精确，高质量的场景。在线重建的场景作为一个有着大致正确的几何轮廓的稠密初始化，经过了高斯的自适应密度控制优化，发现得到的场景质量仍可以取得显著提升，这种提升是基于NeRF的方法所不具有的。结果可以从定性和定量上体现。从定量角度，我们评估了重建场景在线和离线的PSNR，SSIM，LPIPS，如图中所示，可以看出场景能够得到得到快速和显著的优化，PSNR上升了多少。从定性角度，渲染质量提高。。
		- 通过实现在线-离线的转换，我们也实现了离线数据通过在线阶段的反馈得到。我们还制作了测试集，用于评估未观测视角上的渲染质量，即我们方法的泛化性，我们的平均结果PSNR得到多少。。在有限步数以内我们仍有未观测到的地方，测试集的psnr也提高了
		- ps：之后的实验思路可以是在线对离线的影响
- 消融实验
	- 实验A：opacity & volume
	  collapsed:: true
		- Only Opacity，受视角影响，有时会关注近处面积很大但是实际体积并不大的空洞，而忽略远处的更大体积的房间。
		- Opacity策略帮助发现狭窄通道内的更多区域，Volume策略帮助避免陷入局部视角观测的较大的空洞导致完整度上升停滞，两者共同作用让优化过程的上限更高，收敛更快。
	- 实验B：online viewpoint strategy
	  collapsed:: true
		- random在步数足够的时候保持探索完整由于维诺图的完备性；在步数不够的时候没有目标驱动随机探索，探索效率低。
		- Position在有限步数情况下，由贪心的不确定性驱动，探索效率提高。
		- rotation在Position的基础上加上局部环视可以观察到更细粒度的信息，但是由于多了旋转会消耗步数，在有限的步数情况下，有可能导致增益没有position多，但是在步数足够的情况下，结果会好于Position。
		- All 策略在多连接节点中加入了旋转观测，在保持全局覆盖率一定优势的同时，提升了场景重建的细粒度精度。我们发现，在某些场景中（例如 Greigsville 和 YmJkqBEsHnH），过多的多连接节点数量导致 1000 步内的步数消耗较高。当步数足够时，优势最大。
	- 实验C：不同的离线策略
	  collapsed:: true
		- 我们的实验设置：我们探究了两种因素对离线优化过程的影响，其中
		- 深度约束可以让场景的几何更精确（从depth l1看出）因而提高泛化性，但对场景的外观影响不大（从psnr看出）
		- 二维的扁平化高斯参数表征和深度与法向正则项让深度更准确，让场景的泛化性比三维表征只用颜色优化有更高的上限
-
-
- 我的思路
  collapsed:: true
	- 我们的整个问题设定是ASLAM问题[[Active Mapping and Robot Exploration: A Survey](https://addi.ehu.es/bitstream/handle/10810/51106/sensors-21-02445.pdf?sequence=1&isAllowed=y)]
	- 主动感知active perception是指在没有先验信息的情况下对环境进行建模并计算实现它所需的动作。因此，这个算法包括两个过程，环境本身的重建和传感器的运动控制。这种方法被称为主动建图active mapping，即必须在有限时间内构建未知环境的地图，优化结果模型的准确性以及为此目需执行的操作。
	- 环境本身重建对应方法论B，传感器动作控制对应方法论C
	-
	- p.s. all 从信息角度出发，不确定性也是为了反映信息
	- 类似于人类的视觉中的眼睛看向某个位置从周围环境中获取信息，agent通过传感器相机在某个视点进行观测来感知周围的环境信息从而完成重建。“视点”可以理解为agent的相机观察三维场景的特定的角度。在自由空间中，视点的个数是无限多的，agent如何选择至关重要。
	- 我们想要实现的是在有限资源的条件下最大化探索效率，当给定agent设备本身有限时这个问题转化为在短时间内把环境探索完整，即给定步数下达到尽可能高的完整度。
	- 我们需要提高视点选择的效率，首先我们需要保证我们的视点是安全可达的(不能让agent因为去往这个视点而和周围物体产生碰撞)，其次我们不能从这无限多个视点中选择因为这会增加决策的负担，而且是随着探索空间的逐渐增大这个本身就无限的集合会爆炸式增长。所以我们需要将视点备选的集合从无限个压缩到有限个同时是在不改变整个场景的信息量的情况下，即这些有限个视点依旧能代表整个自由空间。（有限的，代表性的，想想维诺图怎么说，这个不能全部保证）
	- 我们需要选择“好的视点”，对于视点好坏的评定并不绝对，但直观上讲我们认为一个较好的视点含有较多的信息增益[《Viewpoint Selection using Viewpoint Entropy》VMV 2001Stuttgart, Germany, November 21–23, 2001]。这样我们在观测完这些挑选出的有限视点后能获得关于环境的最多的信息(相比于其他选择视点的策略)。
	-
	- 在这种情况下，我们选择了维诺图作为我们选择视点的重要的数据结构。
	- 首先，维诺图保证安全可达性(不会和障碍物相撞)而且能覆盖所有场景。
	- 其次，我们的维诺图是稀疏的，节点个数有限(position)，在节点上看向的方向(rotation)也是有限的。我们通过position和rotation解耦让整个候选集合变为有限。
	- 而且，维诺图具有拓扑性，能够描述多联通的关系，而多联通节点是不同路径的交汇，这里会潜在的还有更多信息。
	- 维诺图可以通过渲染实时获取。
	-
	- 如何评估一个视点的信息多少，我们利用不确定性量化来评估信息增益。
	  collapsed:: true
		- 说opacity，render：
			- opacity：当我们选定一个视点渲染出这个视点下的观测，如果这里已经重建好那么这里就有高斯，opacity就大，不确定性就低，这个视点下含有的信息增益就少；同理，没有渲染好的地方没有高斯，这通过opacity低体现出来，这种区域不确定性高，这个视点下含有的信息增益就高，我们需要看向不确定性高的区域去降低整个场景的不确定性，即获取更多信息，具体来说是通过向没有高斯的地方添加高斯来填补空白。
			- render：而利用3dgs的opacity其实就是利用渲染silhouette，渲染可见性，正好是splatam中的，我们进行巧妙利用，而且render实时的特性可以得到在线反馈。 基于视点的渲染，梯度回传，加高斯后得到优化(不确定这个要不要放在渲染里面，splatam那里应该说过这个)。
		- 说panorama：在维诺图的一个节点上，我们如何获得这个节点各个方位的完整的不确定性信息，需要通过360环视去渲染一张全景图。
		- 说opacity+panorama：聚类，
		- 说volume：发现前者视角相关，距离相关，当我们发现一个hole时，由于渲染是视角相关的，具有近大远小的特点，也就是说可能会存在一个距离近的hole opacity为空的像素数量比较大但实际体积比较小，而一个距离远的hole opacity为空的像素数量。所以我们整合3D体积信息去进行更合理的不确定性推断，即加入hole周围一圈包络点云的凸包体积。
	-
	- 如何遍历这些候选节点让我们的收益最大化，Next Best View问题：我们position和rotation贪心的解耦策略
	  collapsed:: true
		- position让我们优先去往不确定性最高的节点，rotation在这个节点看向不确定性最高的方向。自适应粒度：position是粗粒度，rotation是细粒度。可以在这里写position的node scoring策略         “目标驱动？”
		- 同时在去往的路上，我们看向多联通节点不确定性高的方向去获取更多信息。
		- 动态更新每个节点的不确定性信息，这也就是我们的反馈机制，在线反馈和在线决策
	- 我们本质上是在进行位姿优化，视点优化？
-
- 我觉得有点问题的：我们在选position时只是算了in horizon和unarrive的权重？我们有算distance嘛？
- 迪杰斯特拉：路径成本？
- 我们和NeRF+拓扑图的区别？保证场景探索完整条件下，相比于基于表面点选择，我们的候选视点更加稀疏？
- 其他人的用frontier去明确定义是否探索，我们基于渲染
-
- 我们和gs-planner的区别，一定要体现出来
- 维诺图：Simplified Voronoi Diagrams
-
- 参考网页：
	- https://leohope.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/12/01/ViewPoint-Entropy/ 视点熵
	- https://www.cnblogs.com/jinjun517/p/15043072.html 主动探索中文翻译