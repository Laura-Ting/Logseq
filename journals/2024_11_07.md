- Semantic Segmentation(only semantic) or Panoptic Segmentation(semantic+instance)，感觉是不是还是后者更合理一点，如果要找特定房间下的东西，可能是凌乱的，牙刷也可能在卧室。其实感觉是不是可以加一点物理属性的判断，比如说大的东西，沉重的东西会一般不会被移动，小的东西可能被移动走
- 这个准确度怎么算？只要是不同就算错嘛，能否模糊一点，语义相近的有可能
-
-
-
-
- 楼层的计算：所有的楼层预测和gt节点，一一对应的上下边界距离，差值<0.5算正确，边界是否匹配，计算混淆矩阵
- 房间的计算：构造关联矩阵，gt和pred的BEV的重叠比率，最大的加起来，然后除以总数，计算总体精度和召回率
- 物体的计算：可以根据边界框的IoU，也可以根据点云重叠比率，也是计算关联矩阵，找到最佳匹配。计算不同阈值下的准确率，精确率，召回率，计算平均AP
-
- top250和500？总共真值就247个
-
- 他的metric是怎么定义的，到底有没有类别，结合论文图表查明
- 应该有instance-level和semantic-level(只要在一起，碎的也可以)
- 每个指标的含义，acc，percison
- 如何面对重叠覆盖情况，如果超出一点或者少一点
- 按理说一个大，另一个应该小，但是为什么两者一样
- 一个碎片关联多个物体？top-k是怎样定义的，如果有一个算进去就是嘛
- 破碎的粒度应该有体现
- ![](https://i-blog.csdnimg.cn/blog_migrate/71c2a9306208a1f0498a0dda02af23c9.jpeg)
- ![](https://img2020.cnblogs.com/blog/1850883/202006/1850883-20200620075748335-1823678697.png)
-
- recall和precision是相互矛盾的。如果想要更高的recall，那么就要让模型的预测能覆盖到更多的样本，但是这样模型就更有可能犯错，也就是说precision会比较低。如果模型很保守，只能检测出它很确定的样本，那么其precision会很高，但是recall会相对低。
- recall（TPR）的分母是样本中正类的个数，因此样本一旦确定，其分母即为定值，也就是说recall的变化随分子增加而单调递增；precision的分母是样本中预测为正类的个数，其会随着分类阈值的变化而变化，因此Precision的变化受TP和FP的综合影响，不单调，变化情况不可预测。
-
-
-
- 最左上角的确实不是1，是0.998
-
-
- id:: 6730c6bd-8158-4079-85ec-557fe24de010