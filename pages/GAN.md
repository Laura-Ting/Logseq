- Generative Adversarial Nets
- 标题
	- 生成-两大类模型
		- 分辨模型：对于一个模型怎么预测他的类别，或者预测一个实数的值
		- 生成模型：怎么样生成这个数据本身
- 摘要
	- 提出一个框架，用于估计生成模型，通过对抗过程，同时训练两个模型
	- G生成模型：用于捕获数据分布，尽量让辨别模型犯错
	- D辨别模型：用来估计数据到底是来自真实样本，还是生成的
	- 两人对抗游戏，在任何DG空间中，存在一个独一无二的解
	- 如果G和D是MLP，可以通过误差反传来进行训练，不需要使用任何马尔科夫链
- 介绍
	- 深度学习：对整个数据分布的一个特征的表示，不仅仅是深度神经网络
	- 虽然深度学习在辨别模式上取得了很大的进展，但是生成模型上比较差，难点是要最大化似然函数的时候对概率分布要做很多近似，这个近似带来很大的计算困难
	- 生成模型：造假币，判别模型：警察，两者能力越来越强，最后的结果希望警察分辨不出假币
	- 生成模型：MLP，输入是随机噪音，判别模型也是MLP，直接误差反向传递
- 相关工作
	- 之前的方法：想去构造这个分布函数出来，提供一些参数让它可以学习，这些参数通过最大化似然函数，坏处：去采样一个分布的时候算起来比较难，特别是说维度比较高的时候
	- 现在：不去构造，什么都不知道只是去近似，算起来比较容易
	- 观察到：对于f的期望求导就相当于对本身求导，可以让误差反向传播
	- 类似工作VAEs
	- 辨别模型帮助生成也不太行，egNCE(这个损失函数比较复杂)
	- adversarial examples：构造一些和真样本长得很像的假样本，来测试算法的稳定性
- 模型
	- 最简单的是G和D都是MLP
		- 生成器去学习一个叫Pg的分布，在数据x上面(数据x由分布Pg来控制)，定义一个先验在输入噪音变量pz(z)上，生成模型就是把z映射成x，有一个可学习参数叫θg
		- 辨别器，有可学习参数θz，输出一个标量判断到底是来自真实数据还是生成数据，真实数据就是1，生成数据就是0
		- 训练D的同时也会训练G，G用来最小化log(1-D(G(z)))，如果训练的很好了，log(1-0)=0，其他情况下1-xx是大于0的但小于1，再加上一个log是负的，极端情况下，使用真实数据的log是个负无穷
		- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202404091416163.png)
		- x是采样真实的分布，把x放到D中再加一个log，D(x)=1，logD(x)=0，再采集噪音的分布
		- 对于D来说，在完美情况下这两项都为0，但是如果D不完美，有误分类的问题则都会变成负数形式，所以要最大化D
		- 对于G来说，G来自于第二项让辨别器尽量犯错，要最小化G
		- 纳什均衡
		-