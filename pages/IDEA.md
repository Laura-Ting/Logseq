- 场景图更新的预测？从更自然的物理角度来想，或者是预测的角度来想。物体分为刚性和非刚性的。非刚性物体倾向于发生形变，而刚性几乎不可能发生（在不破坏物体的前提下），这样我们就可以从材质的角度进行区分，比如说床或者被子这种柔软物体。还有就是沉的物体不倾向于被移动，比如说一个非常大的床，或者桌子，没人会闲得没事去搬他。你觉得我这种是个好的想法吗？或者可以被改进嘛？
-
- 对于过分割和欠分割的模拟，感觉是不太行，因为一个东西被分割后可能被识别成任意的东西，并不知道这个数值会怎么变。目前达不到说我即使分得很碎，但是里面的特征都是同一个外面的我最想要的特征。
- 所以很大程度上取决于分割模型，所以如何保证局部一致性进行分割。而不是先分碎再融合。这样融合进去的特征也就是不准的，即使后面后filter的步骤
-
- hovsg的抽帧问题，导致有些东西只看到一眼。能否选择好的视角，根据画面中物体的不确定性去决定我是否多看这个物体，以及怎么在现有观测中选择角度（离线setting），在线的话是主动问题
-
- 可以参照concept-fusion方法看近处物体和看远处物体需要有不同的权重。
-
- From 学长
- Dynamic Scene Graph
- 仿真器中物体解耦，仿真器中实时数字化世界模型更新
- 动态场景中人的重建，关节重映射，具身来模仿学习
-
-
- 在hovsg基础上改
	- 动态选择关键帧
	- 把yoloworld和ours的weighting，filtering接进去
-
- GiftedNav中的**residual network**，是否从什么层抽出来会更好，不同的层的特征都有什么样的特性
-
- 直接用3D segmentation，而非2D是否能够保持语义完整性
-
-
- scene graph开集关系构建，目前scene graph构建关系并没有好好利用
-
- 物体scene-graph细粒度分割，根据功能，利用过分割的特性，功能点，操作点。这样也可以面向未来操作。更general。比如说柜子的话把柜门分解出来，这个柜门是可以被操作的。
-
- RGB分割如何利用深度信息。
-
- 颜色和语义共享，联合优化，NeRF ours已经尝试了效果不是很明显，感觉和网络设计架构有关？
-
- 尝试添加transformer，目前做的东西比较hand-crafted
-
- Gaussian Scene graph一定要利用GS differentiable和ADC的特性。
-
- Gaussian Scene Graph如果用2D Gaussian的surfel来对物体表面分布进行划分node
-
- 平衡的永远只有3个量：memory，accuracy，efficiency