### 第四章 不确定性推理方法
collapsed:: true
	- 基本概念
	  collapsed:: true
		- 不确定性推理
		  collapsed:: true
			- 推理：是从已知事实出发，运用知识推出结论或者证明
			- 不确定性推理：从**不确定性的初始证据**出发，通过运用**不确定性的知识**，最终推出具有一定程度的不确定性但却是合理或者近乎合理的结论的思维过程
		- 表示与度量
		  collapsed:: true
			- 知识不确定性：一般由领域专家给出，数值，知识的静态强度
			- 证据不确定性：用户提供的初始证据，证据的动态强度
			- 不确定性度量：充分表达，便于估计，便于不确定性传递的计算，直观
		- 不确定性匹配算法，阈值选择
		  collapsed:: true
			- 不确定性匹配算法：用来计算匹配双方相似程度的算法
			- 阈值：用来指出相似的“限度”
		- 组合证据不确定性算法
		  collapsed:: true
			- 最大最小方法、Hamacher方法、概率方法、有界方法、Einstein方法等
		- 不确定性传递算法
		  collapsed:: true
			- 把证据和知识的不确定性经过每一步推理/多步推理传递到结论
		- 结论不确定性的合成
	- 可信度方法
	  collapsed:: true
		- 可信度：一个事物为真的相信程度，主观性，经验性
		- C-F模型：基于可信度表示不确定性推理
		- 知识的不确定性表示：IF E THEN H (CF(H, E))
		  collapsed:: true
			- E是知识的前提条件；H是知识的结论
			- CF(H, E)：可信度因子 certainty factor，前提条件与结论的联系强度
			  collapsed:: true
				- 取值范围：[-1, 1]，大于0则H为真且越大越真，小于0则H为假且越小越假，等于0则无关
		- 证据不确定性的表示：CF(E)
		  collapsed:: true
			- 同知识
			- 静态强度CF(H, E)：知识的强度，即当E所对应的证据为真时对H的影响程度
			- 动态强度CF(E)：证据E当前的不确定性程度
		- 组合证据不确定性的算法
		  collapsed:: true
			- 多个单一证据的合取
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141132615.png)
			- 多个单一证据的析取
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141133736.png)
		- 不确定性的传递算法
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141135813.png){:height 50, :width 410}
		- 结论不确定性的合成算法
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141136686.png){:height 269, :width 413}
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141136291.png)
		- 计算的例子见ppt
	- 证据理论
	  collapsed:: true
		- 概率分配函数
			- 样本空间D：D是变量 x 所有可能取值的集合，且D中的元素是互斥的，在任一时刻x 都取且只能取D 中的某一个元素为值
			- 概率分配函数M(A)：领域内的命题A是D的子集
				- 函数M：2^D->[0, 1] ，对任何一个属于D的子集A，命它对应一个数M∈[0，1]，且满足 ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141147528.png){:height 34, :width 93}![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141147112.png){:height 51, :width 111}
		- 信任函数
		- 似然函数
		- 概率分配函数的正交和（证据的组合）
		- 基于证据理论的不确定性推理
	- 模糊推理方法
- ImageNet，2.2万类，2000万 -> 2006 李飞飞 众包 2010年发布，2012年AlexNet，Llya，Hinton 85%
- 一个偏置+多个sigmoid之和
- 所有参数统称θ
- 损失函数L(θ)
- 做成batch的问题
	- 10000个样本，100个样本，梯度迈进的方向不同，但是不会有问题。学习率很重要，学习率需要很小，如果学习率很大会震荡很大
- ReLU：Rectified Linear Unit(ReLU) 负数为0，正数不变
- 两个特定的ReLU相加是Sigmoid
- 传统倾向于Sigmoid，但是深度学习倾向ReLU
- 2012：AlexNet(16.4%)，2014：VGG(7.3%)，GoogleNet(6.7%)，2015：Residual Net(3.57%)
- Fat 没有Deep效果好
- 通用的多类分类器
	- one-hot 向量 y=[1 0 0]T   [0 1 0]T   [0 0 1]T
	- 回归是连续输出，分类要再加一个softmax归一化 e(x) / ∑e
	- 损失：MSE，交叉熵，分类问题中更多会用到交叉熵，因为MSE有时候可能会卡住，周围梯度都相同
- ### 第八章 人工神经网络
- 生物神经网络
- 人工神经网络
- 神经元与神经网络
	- 工作状态：兴奋，抑制
	- 记忆与遗忘
- BP神经网络及其学习方法
	- θ阈值
	- ReLU，Leaky ReLU
- 人工神经网络性能三大要素
- 感知机模型：针对单个神经元模型
- 分类
	- 异或分类不是纯线性的，没有办法用一条直线做到
- 全连接
	- 两层or三层
	- 连接是不跨层的
- 偏置量，哑结点
-
-
- 2024.04.17
- Embodied AI 具身智能 ，现在chatGPT是离身的，但具身是根据从环境交互获得更多信息
- AI两大阵营
	- Hinton，Benjo 危险
	- Yann Lecun，吴恩达 不危险
- 是激活函数实现了非线性的逼近
- 损失函数中一定要包含所有的未知参数w和b，因为优化的时候都要进行优化
-
- 2024.04.22
- Water loo在美国认可高
- Ian GoodFellow GAN的发明者
- science美国，nature英国
- 层数码多之后会出现梯度消失和梯度爆炸
- SVM：结构风险最小化，升维(二维不可分的可能在三维上可分)，对XXT去建模，隐式而非显式
- Hinton提出逐层预训练，但是现在已经不使用，Hinton+Alex+Llya->Google，Microsoft，deepmind，Baidu
- 视频分析：获取上下文信息
-
- 2024.04.24
- 卷积的好处：
	- 局部感受野，局部聚焦
	- 权值共享：模板在滑动时权值是相同的
- 卷积的缺点：
	- 容易过训练，参数空间越大越容易在训练集拟合
	- 池化，不可逆，丢失信息
	- 局部会导致长距离，Attention，动态连接
-