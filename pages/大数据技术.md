- ![3.2 分布式数据库HBase.pdf](../assets/3.2_分布式数据库HBase_1715760379160_0.pdf)
- 分布式数据库HBase
  collapsed:: true
	- 概述
	  collapsed:: true
		- BigTable是一个分布式存储系统，起初用于解决典型的互联网搜索问题
			- 建立互联网索引：每页一行地存储到BigTable里，MapReduce计算作业运行在整张表上，生成索引
			- 互联网搜索：
	- HBase访问接口
	- HBase数据模型
	- HBase的实现原理
	- HBase运行机制
	- HBase应用方案
- ![3.4-Hive.pdf](../assets/3.4-Hive_1716797474656_0.pdf)
- Hive
  collapsed:: true
	- Impala：用于即时交互性查询
	- 简介
	  collapsed:: true
		- *Hive是数据仓库，分钟级别的*
		- Cloudera做了大数据应用部署平台
		- 直接与HDFS和Hbase交互，底层并不是mapreduce，不处理长时间处理任务，而hive底层是MapReduce
	- 系统结构
	  collapsed:: true
		- 使用Hive的Metastore，自己实现了与传统的分布式并行数据库类似的组件，最终执行类似SQL的语句
		- 虚线是Impala，实线是
		- CLI实现命令行和用户接口
		- StateStore资源调度器，创建进程，跟踪所有执行的进程，控制implad
		- Impald：计算进程，核心，和hdfs的namenode或者hbase交换，region上找到想要的数据，执行任务，结果返回其他implad做其他任务，既是任务发布者也是任务执行者
	- 查询过程
	  collapsed:: true
		- 没有所谓的master和slave，所有的计算节点都是等价的
		- implad创建进程，statestore创建
		- implad的三个组件：queryCoordinator查询协调器分解任务，和namenode交换信息，解析树；规划片段；cordinater协调其他implad协调其他任务；queryExcutor将最终结果汇总
	- 和Hive比较
	  collapsed:: true
		- 不同点：
		  collapsed:: true
			- Hive批处理，Impala实时交互
			- 执行的底层逻辑：Hive依赖于底层MapReduce计算框架；Impala将所有任务变成一个执行树
			- Hive内存放不下找外存放；Impala不会利用外存，只使用当前内存
		- 相同点：
		  collapsed:: true
			- 都是用相同的原数据
			- 底层架构hdfs，hbase管理，hadoop
			- 执行：类sql，源操作，先根遍历排序
- ![3.5-Spark.pdf](../assets/3.5-Spark_1716799066384_0.pdf)
- Spark
  collapsed:: true
	- Spark概述：基于内存计算的大数据分布架构
	  collapsed:: true
		- 简介：
		  collapsed:: true
			- 加州伯克利AMP人机物计算协同
			- apache三大分布式计算系统：Hadoop，Spark，Storm
			- Spark用了十分之一的计算资源比Hadoop快3倍
		- 特点
		  collapsed:: true
			- 速度快：自己的DAG执行引擎
			- 容易使用：Scala，Java，Python，R都支持
			- 通用性：强大技术栈，SQL查询，流式计算框(MapReduce的Shuffle太慢，希望用这套框架代替所有的，
			- 模式多样：单机和集群都可以，和hadoop整合也可以，有自己的文件系统)，机器学习，图算法组件
		- Scala简介
		  collapsed:: true
			- 多范式编程语言，兼容Java
			- 并发性，语法简洁
		- Spark和Hadoop对比
		  collapsed:: true
			- Spark放入内存中，不用再取
			- 怎么保证电脑即使崩溃数据也不会丢失：自己的DAG
	- Spark生态系统
	  collapsed:: true
		- 批量数据处理：hadoop
		- 基于历史数据的交互式查询：Cloudera Impala
		- 基于实时数据流的数据处理：Storm
		- 问题：
			- 不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换
			- 不同的软件需要不同的开发和维护团队，带来了较高的使用成本
			- 比较难以对同一个集群中的各个系统进行统一的资源协调和分配
		- Spark提供一套完整的生态系统，基于YARN
		- 组件
			- Spark Core 提供内存计算
			- Spark SQL 提供交互式查询分析
			- Spark Streaming 提供流计算功能
			- MLLib 提供机器学习算法库的组件
			- GraphX 提供图计算
	- Spark运行架构
	  collapsed:: true
		- 基本概念
		  collapsed:: true
			- RDD：弹性分布式数据集，提供了一种高度受限的共享内存模型
			- DAG：反映RDD之间的依赖关系
			- Executor：是运行在工作节点（WorkerNode）的一个进程，负责运行Task
			- Application：用户编写的Spark应用程序，相当于MapReduce中的Job
			- Task：运行在Executor上的工作单元
			- Job：一个Job包含多个RDD及作用于相应RDD上的各种操作
			- Stage：是Job的基本调度单位，一个Job会分为多组Task，每组Task被称为Stage，或者也被称为TaskSet，代表了一组关联的、相互之间没有 Shuffle依赖关系的任务组成的任务集
		- 架构设计
			- Program驱动程序，产生Spark Context管理所有运行的资源，负责资源显示但是不负责资源调度，yarn负责
			- Cluster Manager，相当于Master
			- Worker Node就是Slave，有task和缓存
			- 一个Application就是一个用户程序，由一个Driver和若干个Job构成，一个Job由多个Stage构成，同一个stage里的每条线可以并行执行，MapReduce中所有map都能并行，但是stage之间会有依赖关系，对任务的表达能力更强，能做一些map不能做的东西，spark可以表达顺序
		- 运行基本流程
		  collapsed:: true
			- 构建起基本的运行环境，即由Driver创建一个 SparkContext，可以运行到yarn上去
			- 分配资源，执行Excutor
			- 根据RDD构建DAG图，Scheduler将其解析成不同的Stage，然后把一个个TaskSet提交给底层调度器 TaskScheduler处理；Executor向 SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码
			- Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源
		- RDD运行原理
			- 设计背景
				- 为了机器学习和人工智能设计，中间结果，hdfs会存储复制，这样会有时间损耗，希望
				- 只读，每个RDD有若干分区
			- 运行原理
				- 两类：动作Action和转换Transformation，所有的中间结果都叫转换，只有最后一个叫做Action
				- DAG图：只记住转换的操作，得到DAG拓扑排序，即Lineage血缘关系
			- 特性
				- 高效的容错性：现有容错机制+RDD
				- 中间结果持久化到内存
				- 可以存放Java对象，避免了不必要的对象序列化和反序列化
			- RDD并行化
				- 窄依赖：一个或多个父RDD的分区对应于一个子RDD的分区
				- 宽依赖：一个父RDD的一个分区对应一个子 RDD的多个分区
			- Stage划分
			  collapsed:: true
				- 在DAG中进行反向解析，遇到宽依赖就断开
				- 遇到窄依赖就把当前的RDD加入到Stage中
				- 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算
				- eg
					- A->B宽依赖，不能并行操作，把A单独变为Stage
					- C->D,E->F窄依赖，加进去
					- F->G一个新的分区
				- 两种Stage
					- ShuffleMapStage：不是最终的Stage，在它之后还有其他Stage
					- ResultStage：最终的Stage，没有输出，而是直接产生结果或存储
			- RDD在Spark架构中的运行过程
			  collapsed:: true
				- 创建RDD对象
				- SparkContext负责计算RDD之间的依赖关系，构建DAG
				- DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行
-
- ![4 理解数据.pdf](../assets/4_理解数据_1717574881493_0.pdf)
- 理解数据
  collapsed:: true
	- 主要任务：EDA(exploratory data analysis)
	  collapsed:: true
		- 任务一：每个属性取值分布统计
		  collapsed:: true
			- 对给定数据集的各个属性的取值分布情况进行统计概括，方差，平均值
			- 宽表：把所有数据放到一个表中
		- 任务二：多个属性取值分布统计
		  collapsed:: true
			- 对给定数据集的多个属性的取值分布情况进行统计概括
		- 任务三：数据的总体质量评估
		  collapsed:: true
			- 数据存在误差属性值缺失噪声和不一致性等潜在的数据质量问题
	- 基于统计描述的数据理解方法
		- 集中趋势度量
			- 数值型数据
				- 均值
					- 简单平均数
						- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406051629784.png){:height 48, :width 212}
					- 截尾均值
						- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406051630474.png){:height 49, :width 259}
				- 分位数
				- 几何均值
		- 类别型数据
			- 众数
-
-
- 回顾
	- 什么是大数据：数据量大，种类多（不同的传感器观察手段拿来的数据是不同的），4v
	- 大数据和云计算：云计算的优点，急卖急用，计算资源，技术基础，大数据的挖掘产生价值
	- 大数据和物联网：大数据的重要来源，数据整理成一个宽表
	- HDFS：spark和flink的底层，是整个的基础，存储，大数据的存储容易发生异常，冗余存储的保证，hdfs的put和get等操作
	- hbase：数据结构是也是二维表，列族的概念，需要五元组确定一个位置，稀疏，storefile是最小的检索单元，route存到zukeeper，上面有meta表，每个region有hlog，region的分裂和结合该清楚
	- mapreduce，map映射key和value值，map阶段需要shuffle
	- hive数据仓库，底层没有分布式架构，用户接口和cli和hwi和jdbc-connector，odbc是自己的，借助mysql存储，把hiveql执行成hive操作单元
	- impladad 为了解决hive的缺陷，既能管理任务又能执行任务
	- spark：uc伯克利，有一套并行操作分解为若干stage，计算模式从mapreduce进一步扩展，支持受限内存访问单元，自己的mllibrary，dag，scheler，可并行的变成taskset，交给每个excutor执行，但是spark在流处理不太好，只能在秒级，而不能毫秒级
	- flink，所有数据源放在消息缓冲队列，eg kafka，计算，计算结果再存到消息队列中，取代了集中式的大型数据库，内存中运行的很快，存到结果数据库中，完成批流一体化
	-