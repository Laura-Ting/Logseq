- ![1-第1章 绪论（导论5）.pdf](../assets/1-第1章_绪论（导论5）_1717297539102_0.pdf)
- 一，绪论
  collapsed:: true
	- 人工智能的基本概念
	  collapsed:: true
		- 智能的概念
		- 智能的特征
		- 人工智能
	- 人工智能的发展简史
	  collapsed:: true
		- 孕育
		- 形成
		- 发展
		- 大数据驱动发展期
	- 人工智能研究的基本内容
	  collapsed:: true
		- 知识表示
		- 机器感知
		- 机器思维
		- 机器学习
		- 机器行为
	- 人工智能的主要研究领域
	  collapsed:: true
		- 自动定理证明
		- 博弈
			- 棋类游戏的计算复杂性
			- 国际象棋比赛
			- 围棋比赛
		- 模式识别
		- 机器视觉
		- 智慧医疗
		- 自然语言理解
		- 机器听觉
		- 机器翻译
		- 智能信息检索
		- 数据挖掘与知识发现
		- 专家系统
		- 自动程序设计
		- 机器人
		- 组合优化问题
		- 智慧物流
		- 人工神经网络
		- 分布式人工智能与多智能体
		- 智能控制
		- 智能仿真
		- 智能CAD
		- 智能CAI
		- 智能管理与智能决策
		- 智能多媒体系统
		- 智能操作系统
		- 智能计算机系统
		- 智能通信
		- 智能网络系统
		- 人工生命
- ![2-第2章 知识表示与知识图谱（导论5）.pdf](../assets/2-第2章_知识表示与知识图谱（导论5）_1717297552405_0.pdf)
- 二，知识表示与知识图谱
  collapsed:: true
	- 知识与知识表示的概念
	  collapsed:: true
		- 知识的概念
		  collapsed:: true
			- 定义：把有关信息关联在一起所形成的信息结构，反应不同关系
			- 分为事实和规则
		- 知识的特性
		  collapsed:: true
			- 相对正确性：在一定情况和条件下知识才是正确的
			- 不确定性：可能由随机性，模糊性，经验，不完全性引起
			- 可表示性和可利用性
		- 知识的表示
		  collapsed:: true
			- 将人类知识形式化，模型化
			- 选择表示方法的原则
				- 充分表示领域知识
				- 有利于对知识的利用
				- 便于对知识组织，维护与管理
				- 便于理解与实现
	- 一阶逻辑谓词表示法
	  collapsed:: true
		- 命题
		  collapsed:: true
			- 真命题，假命题
			- 命题逻辑：研究命题及命题之间关系的符号逻辑系统
			- 命题逻辑表示方法：无法反映事物的结构，无法表述不同事物间的共同特征
		- 谓词：P(x1, x2, x3..., xn)
		  collapsed:: true
			- 个体x1...xn，谓词名P
			- 个体可以是常量，变元，函数，谓词
		- 谓词公式
		  collapsed:: true
			- 连接词：否定/非，析取/或，合取/与，蕴含/条件，等价/双条件
			- 量词：全称量词(任意x)，存在量词(存在x)
			- 谓词公式
			  collapsed:: true
				- 单个谓词是谓词公式，称为原子谓词公式
				- 若A是谓词公式，﹁A，A∧B，A∨B，A→B， A⟷B，任意A，存在A也都是谓词公式
				- 连接词的优先级别从高到低排列：﹁， ∧， ∨， →， <->
			- 量词的辖域
			  collapsed:: true
				- 量词的辖域：这个量词所管辖的地方，比如(存在x)(P(x, y) → Q (x, y))∨R(x, y)中(P(x, y) → Q (x, y))是(存在x)的辖域
				- 约束变元与自由变元：辖域内与量词中同名的变元称为约束变元，不同名的变元称为自由变元，比如(P(x, y) → Q (x, y))中的x是约束变元，R(x, y)是自由变元
		- 谓词公式的性质
		  collapsed:: true
			- 谓词公式的解释
			  collapsed:: true
				- 谓词公式在个体域上的解释，比如Friends (george, x)，可以有Friends (george, susie)=T，Friends (george, kate)=F的解释
				- 对于每一个解释，谓词公式都可求出一个真值（T或F）
			- 谓词公式的永真性，可满足性，不可满足性
			  collapsed:: true
				- 永真性：谓词公式P在所有D上都取得真值T
				- 永假性：谓词公式P在所有D上都取得真值F
				- 可满足性：如果至少存在一个解释使得P在此解释下的真值为T，则称P是可满足的，否则，则称P是不可满足的
			- 谓词公式的等价性
			  collapsed:: true
				- P和Q对于共同的个体域D上任意解释都有相同的真值，P<=>Q
			- 谓词公式的永真蕴含
			  collapsed:: true
				- 如果P→Q永真，则称公式P永真蕴含Q，且称Q为P的逻辑结论，称P为Q的前提，记为P=>Q
			- 谓词逻辑的其他推理规则
			  collapsed:: true
				- P规则：前提引入
				- T规则：使用永真蕴含公式S，推理规则
				- CP规则：如果命题R和前提能推出S，则使用R->S，附加前提引入
				- 反证法：P=>Q，当且仅当P∧﹁Q<=>F（P∧﹁Q不可满足）
		- 一阶逻辑知识表示方法
		  collapsed:: true
			- 谓词公式表示知识的步骤
			  collapsed:: true
				- 定义谓词及个体
				- 变元赋值
				- 用连接词连接各个谓词，形成谓词公式
		- 一阶逻辑表示法的特点
		  collapsed:: true
			- 优点：自然性，精确性，严密性，容易实现
			- 局限性：不能表示不确定的知识，组合爆炸，效率低
			- 应用：自动问答系统，机器人行动规划系统，机器博弈系统，问题求解系统
	- 产生式表示法
	  collapsed:: true
		- 产生式
		  collapsed:: true
			- 适合：表示事实性知识和规则性知识
			- 确定性规则知识的产生式表示
			  collapsed:: true
				- IF P THEN Q，或者P->Q
			- 不确定性规则知识的产生式表示
			  collapsed:: true
				- IF P THEN Q （置信度），或者P->Q（置信度）
			- 确定性事实性知识的产生式表示
			  collapsed:: true
				- 三元组表示（对象，属性，值）
			- 不确定性事实性知识的产生式表示
			  collapsed:: true
				- 四元组表示（对象，属性，值，置信度）
			- 产生式与谓词逻辑中的蕴含式的区别
			  collapsed:: true
				- 除逻辑蕴含外，产生式还包括各种操作、规则、变换、算子、函数等
				- 蕴含式只能表示精确知识，产生式还可以表示不精确知识
			- 产生式的形式描述及语义：
			  collapsed:: true
				- 符号表示：“::=”表示“定义为”；符号“|”表示“或者是”；符号“[ ]”表示“可缺省”
				- BNF
				  collapsed:: true
					- <产生式>::=<前提>-><结论>
					- <前 提>::=<简单条件>|<复合条件>
					- <结 论>::=<事实>|<操作>
					- <复合条件>::=<简单条件>AND<简单条件>[AND<简单条件>…|<简单条件>OR<简单条件>[OR<简单条件>…
					- <操 作>::=<操作名>[(<变元>，…)]
		- 产生式系统
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406030903629.png){:height 199, :width 447}
			- 规则库: 用于描述相应领域内知识的产生式集合
			- 综合数据库(事实库、上下文、黑板等)：一个用于存放问题求解过程中各种当前信息的数据结构
			- 控制系统（推理机构）：由一组程序组成，负责整个产生式系统的运行，实现对问题的求解
			  collapsed:: true
				- 从规则库中选择与综合数据库中的已知事实进行匹配
				- 匹配成功的规则可能不止一条，进行冲突消解
				- 执行某一规则时，如果其右部是一个或多个结论，则把这些结论加入到综合数据库中：如果其右部是一个或多个操作，则执行这些操作
				- 对于不确定性知识，在执行每一条规则时还要按一定的算法计算结论的不确定性
				- 检查综合数据库中是否包含了最终结论，决定是否停止系统的运行
		- 产生式系统——动物识别系统
		- 产生式表示法的特点
		  collapsed:: true
			- 优点：自然性，模块性，有效性，清晰性
			- 缺点：效率不高，不能表达结构性知识
		- 适合产生式表示的知识
		  collapsed:: true
			- 领域知识间关系不密切，不存在结构关系
			- 经验性及不确定性的知识，且相关领域中对这些知识没有严格、统一的理论
			- 领域问题的求解过程可被表示为一系列相对独立的操作，且每个操作可被表示为一条或多条产生式规则
	- 框架表示法
	  collapsed:: true
		- 概要：一种结构化的知识表示方法
		- 框架的一般结构
		  collapsed:: true
			- 框架：一种描述所论对象（一个事物、事件或概念）属性的数据结构
			  collapsed:: true
				- 一个框架由若干个被称为“槽”（slot）的结构组成，每一个槽又可根据实际情况划分为若干个“侧面”（faced）
				- 槽相当于属性，侧面相当于属性的一个方面
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406030913773.png){:height 233, :width 278}
			- 事例框架：把具体的信息填入槽或侧面后
		- 特点：结构性，继承性，自然性
	- 知识图谱
	  collapsed:: true
		- 概要：知识图谱是一种互联网环境下的知识表示方法，2012年谷歌提出
		- 定义：用各种不同的图形等可视化技术描述知识资源及其载体，挖掘、分析、构建、绘制和显示知识及它们之间的相互联系
		  collapsed:: true
			- 由一些相互连接的实体及其属性构成
			- 三元组：(实体1-关系-实体2)，(实体-属性-属性值)
		- 表示：图，节点表示实体/概念，边表示关系/属性
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406030923978.png){:height 250, :width 367}
		- 架构：
		  collapsed:: true
			- 逻辑结构：模式层和数据层
				- 数据层主要是由一系列的事实组成，而知识以事实为单位进行存储
				- 模式层构建在数据层之上，是知识图谱的核心
			- 体系架构
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202406030921858.png){:height 186, :width 443}
			- 资源对象：结构化数据，半结构化数据，非结构化数据
		- 构建：
		  collapsed:: true
			- 自顶向下：先为知识图谱定义好本体与数据模式，再将实体加入到知识库
			- 自底向上：从一些开放链接数据中提取出实体，选择其中置信度较高的加入到知识库，再构建顶层的本体模式
		- 典型应用：维基百科，DBpedia，YAGO，XLORE
- ![3-第3章 确定性推理方法（导论5）.pdf](../assets/3-第3章_确定性推理方法（导论5）_1717297562681_0.pdf)
- 三，确定性推理方法
	- 推理的基本概念
		- 推理的定义：根据数据库中的已知事实(证据)和知识库中的知识，基于某种策略得出结论
		- 推理方式及其分类
			- 演绎推理、归纳推理、默认推理
				- 演绎推理：三段论式（大前提，小前提，结论），一般 → 个别
				- 归纳推理：个别 → 一般，分为完全归纳推理（必然性推理），不完全归纳推理（非必然性推理）
				- 默认推理/缺省推理：知识不完全的情况下假设某些条件已经具备所进行的推理
			- 确定性推理、不确定性推理
				-
			- 单调推理、非单调推理
			- 启发式推理、非启发式推理
		- 推理的方向
			- 正向推理
			- 逆向推理
			- 混合推理
			- 双向推理
		- 冲突消解策略
	- 自然演绎推理
- ![4-第4章 不确定性推理方法（导论5）.pdf](../assets/4-第4章_不确定性推理方法（导论5）_1717297572678_0.pdf)
- 四，不确定性推理方法
- ![5-第5章 搜索求解策略（导论5）.pdf](../assets/5-第5章_搜索求解策略（导论5）_1717297581943_0.pdf)
- 五，搜索求解策略
- ![6-第6章 智能计算及其应用（导论5）.pdf](../assets/6-第6章_智能计算及其应用（导论5）_1717297589978_0.pdf)
- 六，智能计算及其应用
- ![7-第7章 专家系统（导论5）.pdf](../assets/7-第7章_专家系统（导论5）_1717297597460_0.pdf)
- 七，专家系统
- ![8-补充1-模式识别系统.pdf](../assets/8-补充1-模式识别系统_1717297604972_0.pdf)
- 八，模式识别系统
- ![9-补充2-模型评估方法.pdf](../assets/9-补充2-模型评估方法_1717297613425_0.pdf)
- 九，模型评估方法
- ![10-补充3-机器学习模型类型.pdf](../assets/10-补充3-机器学习模型类型_1717297620758_0.pdf)
- 十，机器学习模型类型
- ![11-补充4-线性模型与非线性扩展.pdf](../assets/11-补充4-线性模型与非线性扩展_1717297628172_0.pdf)
- 十一，线性模型与非线性扩展
- ![12-第8章 人工神经网络及其应用（导论5）-修订.pdf](../assets/12-第8章_人工神经网络及其应用（导论5）-修订_1717297636035_0.pdf)
- 十二，自然语言处理及其应用
-
- ### 第四章 不确定性推理方法
  collapsed:: true
	- 基本概念
	  collapsed:: true
		- 不确定性推理
		  collapsed:: true
			- 推理：是从已知事实出发，运用知识推出结论或者证明
			- 不确定性推理：从**不确定性的初始证据**出发，通过运用**不确定性的知识**，最终推出具有一定程度的不确定性但却是合理或者近乎合理的结论的思维过程
		- 表示与度量
		  collapsed:: true
			- 知识不确定性：一般由领域专家给出，数值，知识的静态强度
			- 证据不确定性：用户提供的初始证据，证据的动态强度
			- 不确定性度量：充分表达，便于估计，便于不确定性传递的计算，直观
		- 不确定性匹配算法，阈值选择
		  collapsed:: true
			- 不确定性匹配算法：用来计算匹配双方相似程度的算法
			- 阈值：用来指出相似的“限度”
		- 组合证据不确定性算法
		  collapsed:: true
			- 最大最小方法、Hamacher方法、概率方法、有界方法、Einstein方法等
		- 不确定性传递算法
		  collapsed:: true
			- 把证据和知识的不确定性经过每一步推理/多步推理传递到结论
		- 结论不确定性的合成
	- 可信度方法
	  collapsed:: true
		- 可信度：一个事物为真的相信程度，主观性，经验性
		- C-F模型：基于可信度表示不确定性推理
		- 知识的不确定性表示：IF E THEN H (CF(H, E))
		  collapsed:: true
			- E是知识的前提条件；H是知识的结论
			- CF(H, E)：可信度因子 certainty factor，前提条件与结论的联系强度
			  collapsed:: true
				- 取值范围：[-1, 1]，大于0则H为真且越大越真，小于0则H为假且越小越假，等于0则无关
		- 证据不确定性的表示：CF(E)
		  collapsed:: true
			- 同知识
			- 静态强度CF(H, E)：知识的强度，即当E所对应的证据为真时对H的影响程度
			- 动态强度CF(E)：证据E当前的不确定性程度
		- 组合证据不确定性的算法
		  collapsed:: true
			- 多个单一证据的合取
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141132615.png)
			- 多个单一证据的析取
				- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141133736.png)
		- 不确定性的传递算法
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141135813.png){:height 50, :width 410}
		- 结论不确定性的合成算法
		  collapsed:: true
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141136686.png){:height 269, :width 413}
			- ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141136291.png)
		- 计算的例子见ppt
	- 证据理论
	  collapsed:: true
		- 概率分配函数
			- 样本空间D：D是变量 x 所有可能取值的集合，且D中的元素是互斥的，在任一时刻x 都取且只能取D 中的某一个元素为值
			- 概率分配函数M(A)：领域内的命题A是D的子集
				- 函数M：2^D->[0, 1] ，对任何一个属于D的子集A，命它对应一个数M∈[0，1]，且满足 ![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141147528.png){:height 34, :width 93}![Replaced by Image Uploader](https://raw.githubusercontent.com/qugushihua/blog-images/master/202403141147112.png){:height 51, :width 111}
		- 信任函数
		- 似然函数
		- 概率分配函数的正交和（证据的组合）
		- 基于证据理论的不确定性推理
	- 模糊推理方法
- ImageNet，2.2万类，2000万 -> 2006 李飞飞 众包 2010年发布，2012年AlexNet，Llya，Hinton 85%
- 一个偏置+多个sigmoid之和
- 所有参数统称θ
- 损失函数L(θ)
- 做成batch的问题
	- 10000个样本，100个样本，梯度迈进的方向不同，但是不会有问题。学习率很重要，学习率需要很小，如果学习率很大会震荡很大
- ReLU：Rectified Linear Unit(ReLU) 负数为0，正数不变
- 两个特定的ReLU相加是Sigmoid
- 传统倾向于Sigmoid，但是深度学习倾向ReLU
- 2012：AlexNet(16.4%)，2014：VGG(7.3%)，GoogleNet(6.7%)，2015：Residual Net(3.57%)
- Fat 没有Deep效果好
- 通用的多类分类器
	- one-hot 向量 y=[1 0 0]T   [0 1 0]T   [0 0 1]T
	- 回归是连续输出，分类要再加一个softmax归一化 e(x) / ∑e
	- 损失：MSE，交叉熵，分类问题中更多会用到交叉熵，因为MSE有时候可能会卡住，周围梯度都相同
- ### 第八章 人工神经网络
- 生物神经网络
- 人工神经网络
- 神经元与神经网络
	- 工作状态：兴奋，抑制
	- 记忆与遗忘
- BP神经网络及其学习方法
	- θ阈值
	- ReLU，Leaky ReLU
- 人工神经网络性能三大要素
- 感知机模型：针对单个神经元模型
- 分类
	- 异或分类不是纯线性的，没有办法用一条直线做到
- 全连接
	- 两层or三层
	- 连接是不跨层的
- 偏置量，哑结点
-
-
- 2024.04.17
- Embodied AI 具身智能 ，现在chatGPT是离身的，但具身是根据从环境交互获得更多信息
- AI两大阵营
	- Hinton，Benjo 危险
	- Yann Lecun，吴恩达 不危险
- 是激活函数实现了非线性的逼近
- 损失函数中一定要包含所有的未知参数w和b，因为优化的时候都要进行优化
-
- 2024.04.22
- Water loo在美国认可高
- Ian GoodFellow GAN的发明者
- science美国，nature英国
- 层数码多之后会出现梯度消失和梯度爆炸
- SVM：结构风险最小化，升维(二维不可分的可能在三维上可分)，对XXT去建模，隐式而非显式
- Hinton提出逐层预训练，但是现在已经不使用，Hinton+Alex+Llya->Google，Microsoft，deepmind，Baidu
- 视频分析：获取上下文信息
-
- 2024.04.24
- 卷积的好处：
	- 局部感受野，局部聚焦
	- 权值共享：模板在滑动时权值是相同的
- 卷积的缺点：
	- 容易过训练，参数空间越大越容易在训练集拟合
	- 池化，不可逆，丢失信息
	- 局部会导致长距离，Attention，动态连接
-